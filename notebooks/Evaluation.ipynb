{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c65b45",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2b5a1",
   "metadata": {},
   "source": [
    "### Inhalt\n",
    "\n",
    "Detailierte Beschreibung des Quellcodes Basis-Evaluation. \n",
    "\n",
    "Der Quellcode ist funktional gegliedert. Das heißt in einer Zelle wird eine inhaltlich separierbare Funktion ausgefüllt.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ed285",
   "metadata": {},
   "source": [
    "**Schritt 1**\n",
    "Im ersten Schritt werden die relevanten Bibliotheken für die Evaluation eingebunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ade34",
   "metadata": {},
   "source": [
    "**Schritt 2**\n",
    "Im zweiten Schritt werden die relevanten Pfade zu den benötigten Dateien angelegt:\n",
    "- Datensatz german.data\n",
    "- Künstliches Neuronales Netz german_credit_model.keras\n",
    "- Diverse Profile aus dem German Credit Datensatz diverse_profiles.csv\n",
    "- Profilbericht über die Ergebnisse der beiden Metriken. Dieser wird durch die Evaluation generiert und als profilbericht_alpha_beta_twostage.md abgespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Pfade ---\n",
    "DATA_PATH = \"c:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Datensatz/german.data\"\n",
    "MODEL_PATH = \"c:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/german_credit_model.keras\"\n",
    "PROFILES_CSV = \"c:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/diverse_profiles.csv\"\n",
    "REPORT_PATH = \"c:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/profilbericht_alpha_beta_twostage.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5229e",
   "metadata": {},
   "source": [
    "**Schritt 3**\n",
    "Hier wird über DATA_PATH der German-Credit-Datensatz eingelesen und die Struktur definiert:\n",
    "- Spaltennamen werden vergeben \n",
    "- Die Zielvariable wird auf binär gemappt {1→1 (good), 2→0 (bad)}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63639080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden & Vorverarbeitung\n",
    "df = pd.read_csv(DATA_PATH, header=None, sep=r\"\\s+\")\n",
    "df.columns = [\n",
    "    \"Status_des_Girokontos\", \"Dauer_in_Monaten\", \"Kreditgeschichte\", \"Kreditverwendungszweck\",\n",
    "    \"Kreditbetrag\", \"Sparkonto_Wertpapiere\", \"Beschäftigt_seit\", \"Ratenhöhe\",\n",
    "    \"Familienstand_Geschlecht\", \"Weitere_Bürgen_Schuldner\", \"Wohnsitzdauer\", \"Vermögen\", \"Alter\",\n",
    "    \"Andere_Ratenverpflichtungen\", \"Wohnsituation\", \"Anzahl_bestehender_Kredite\", \"Beruf\",\n",
    "    \"Unterhaltspflichtige_Personen\", \"Telefon\", \"Ausländischer_Arbeiter\", \"Ziel\"\n",
    "]\n",
    "df[\"Ziel\"] = df[\"Ziel\"].map({1: 1, 2: 0}).astype(int)\n",
    "\n",
    "X_all = df.drop(columns=[\"Ziel\"])\n",
    "y_all = df[\"Ziel\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18418893",
   "metadata": {},
   "source": [
    "**Schritt 4** Hier werden die kategorischen und numerischen Variablen behandelt \n",
    "- Mit numerical_cols und categorical_cols wird definiert, welche Spalten numerisch und welche kategorisch behandelt werden.\n",
    "\n",
    "- Der ColumnTransformer standardisiert numerische Spalten standardisiert und kategoriale werden one-hot encodiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerisch/Kategorisch\n",
    "numerical_cols = [\n",
    "    \"Dauer_in_Monaten\", \"Kreditbetrag\", \"Ratenhöhe\", \"Wohnsitzdauer\",\n",
    "    \"Alter\", \"Anzahl_bestehender_Kredite\", \"Unterhaltspflichtige_Personen\"\n",
    "]\n",
    "categorical_cols = [c for c in X_all.columns if c not in numerical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numerical_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "])\n",
    "preprocessor.fit(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9d355",
   "metadata": {},
   "source": [
    "**Schritt 5** Hier wird das ANN für die Kreditprognosen geladen\n",
    "\n",
    "- Die Bedingung prüft, ob das Modell im Pfad existiert \n",
    "- Dann wird das Modell mit model geladen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modell laden ---\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Modelldatei fehlt: {MODEL_PATH}\")\n",
    "model = load_model(MODEL_PATH)\n",
    "print(\"Modell erfolgreich geladen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6fe2d",
   "metadata": {},
   "source": [
    "**Schritt 6** Einbindung der 10 diversen Profile \n",
    "\n",
    "- Die 10 Profile werden mittels profiles_df eingelesen und mit  \n",
    "- Es werden überflüssige Spalten entfernt \n",
    "- Die Spalten werden geordnet wie in X_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Profile laden & Spalten ausrichten ---\n",
    "profiles_df = pd.read_csv(PROFILES_CSV)\n",
    "extra_cols = [c for c in profiles_df.columns if c not in X_all.columns]\n",
    "if extra_cols:\n",
    "    profiles_df = profiles_df.drop(columns=extra_cols)\n",
    "profiles_df = profiles_df[X_all.columns]\n",
    "profiles_df[numerical_cols] = profiles_df[numerical_cols].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d19943",
   "metadata": {},
   "source": [
    "**Schritt 7** Ökonomishce und Soziodemographische Features\n",
    "\n",
    "- Die ökonomischen und soziodemographischen Feature-Gruppen werden mit _num und _cat explizit definiert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6edcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feste Feature-Gruppen \n",
    "econ_num = ['Kreditbetrag', 'Dauer_in_Monaten', 'Ratenhöhe', 'Anzahl_bestehender_Kredite']\n",
    "econ_cat = ['Kreditgeschichte', 'Kreditverwendungszweck', 'Sparkonto_Wertpapiere', 'Vermögen',\n",
    "            'Status_des_Girokontos', 'Beschäftigt_seit', 'Andere_Ratenverpflichtungen', 'Weitere_Bürgen_Schuldner']\n",
    "\n",
    "socio_num = ['Alter', 'Wohnsitzdauer', 'Unterhaltspflichtige_Personen']\n",
    "socio_cat = ['Familienstand_Geschlecht', 'Wohnsituation', 'Telefon', 'Ausländischer_Arbeiter', 'Beruf']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347db8c",
   "metadata": {},
   "source": [
    "**Schritt 8** Berechnung der beiden Metriken \n",
    "\n",
    "*α (Notwendigkeit, lokal):*\n",
    "\n",
    "Für jedes Profil & Feature: \n",
    "Jedes Featrue wird isoliert variiert (numerisch über ein Quantil-Grid; kategorial über andere Klassen) → sobald der Output kippt, gilt das Feature als „notwendig“ (1), sonst 0.\n",
    "\n",
    "*β (Suffizienz, lokal):*\n",
    "Für jedes Profil & Feature: \n",
    "Das Feature bleibt stabild und es werden alle anderen Features variiert (durch Sampling aus X_all) → β ist der Anteil der Fälle, in denen der Output gleich bleibt wie beim Profil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# α / β – Funktionen\n",
    "def _predict_label_and_proba(model, preprocessor, row_df, threshold=0.5):\n",
    "    Xp = preprocessor.transform(row_df)\n",
    "    proba = float(model.predict(Xp, verbose=0)[0, 0])\n",
    "    label = int(proba >= threshold)\n",
    "    return label, proba\n",
    "\n",
    "def _numeric_grid_around(value, lo, hi, n_steps=9):\n",
    "    grid = np.linspace(lo, hi, n_steps)\n",
    "    return [v for v in grid if abs(v - value) > 1e-12]\n",
    "\n",
    "def alpha_test_numeric(model, preprocessor, df_row, feature, bounds, threshold=0.5,\n",
    "                       n_steps=9, clip_min=None):\n",
    "    orig_label, _ = _predict_label_and_proba(model, preprocessor, df_row, threshold)\n",
    "    lo, hi = bounds\n",
    "    value = float(df_row[feature].iloc[0])\n",
    "    test_values = _numeric_grid_around(value, lo, hi, n_steps=n_steps)\n",
    "\n",
    "    for v in test_values:\n",
    "        v_clip = float(max(v, clip_min)) if clip_min is not None else float(v)\n",
    "        mod_row = df_row.copy()\n",
    "        mod_row.at[df_row.index[0], feature] = np.float64(v_clip)\n",
    "        new_label, _ = _predict_label_and_proba(model, preprocessor, mod_row, threshold)\n",
    "        if new_label != orig_label:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def alpha_test_categorical(model, preprocessor, df_row, feature, all_categories, threshold=0.5):\n",
    "    orig_label, _ = _predict_label_and_proba(model, preprocessor, df_row, threshold)\n",
    "    current_cat = df_row[feature].iloc[0]\n",
    "    for cat in all_categories:\n",
    "        if cat == current_cat:\n",
    "            continue\n",
    "        mod_row = df_row.copy()\n",
    "        mod_row.at[df_row.index[0], feature] = cat\n",
    "        new_label, _ = _predict_label_and_proba(model, preprocessor, mod_row, threshold)\n",
    "        if new_label != orig_label:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def run_alpha_for_profiles(\n",
    "    model, preprocessor, df_all, profiles_df,\n",
    "    features_numeric, features_categorical,\n",
    "    threshold=0.5, q_lo=0.05, q_hi=0.95, n_steps=9\n",
    "):\n",
    "    if not features_numeric and not features_categorical:\n",
    "        return pd.DataFrame(index=profiles_df.index), pd.Series(dtype=float)\n",
    "\n",
    "    num_bounds = {feat: (float(df_all[feat].quantile(q_lo)),\n",
    "                         float(df_all[feat].quantile(q_hi)))\n",
    "                  for feat in features_numeric}\n",
    "    cat_values = {feat: sorted(df_all[feat].dropna().unique().tolist())\n",
    "                  for feat in features_categorical}\n",
    "\n",
    "    rows = []\n",
    "    for i in profiles_df.index:\n",
    "        row = profiles_df.loc[[i]]\n",
    "        row_result = {}\n",
    "        for feat in features_numeric:\n",
    "            row_result[feat] = alpha_test_numeric(model, preprocessor, row, feature=feat,\n",
    "                                                  bounds=num_bounds[feat], threshold=threshold,\n",
    "                                                  n_steps=n_steps, clip_min=0.0)\n",
    "        for feat in features_categorical:\n",
    "            row_result[feat] = alpha_test_categorical(model, preprocessor, row, feature=feat,\n",
    "                                                      all_categories=cat_values[feat], threshold=threshold)\n",
    "        row_result[\"profile_index\"] = i\n",
    "        rows.append(row_result)\n",
    "\n",
    "    results_table = pd.DataFrame(rows).set_index(\"profile_index\").sort_index()\n",
    "    alpha_per_feature = results_table.mean(axis=0).rename(\"alpha_rate\")\n",
    "    return results_table, alpha_per_feature\n",
    "\n",
    "def _predict_label_and_proba_batch(model, preprocessor, df, threshold=0.5):\n",
    "    Xp = preprocessor.transform(df)\n",
    "    proba = model.predict(Xp, verbose=0).reshape(-1)\n",
    "    labels = (proba >= threshold).astype(int)\n",
    "    return labels, proba\n",
    "\n",
    "def beta_test_feature(\n",
    "    model, preprocessor, df_all, df_row, feature, value=None,\n",
    "    threshold=0.5, n_samples=2000, random_state=42\n",
    "):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    y_star, p_star = _predict_label_and_proba(model, preprocessor, df_row, threshold)\n",
    "    a = df_row[feature].iloc[0] if value is None else value\n",
    "\n",
    "    sample_idx = rng.integers(0, df_all.shape[0], size=n_samples)\n",
    "    Z = df_all.iloc[sample_idx].copy()\n",
    "    if pd.api.types.is_numeric_dtype(df_all[feature]):\n",
    "        Z[feature] = float(a)\n",
    "    else:\n",
    "        Z[feature] = a\n",
    "\n",
    "    y_hat, _ = _predict_label_and_proba_batch(model, preprocessor, Z, threshold)\n",
    "    same = (y_hat == y_star).astype(float)\n",
    "    beta = float(same.mean())\n",
    "\n",
    "    return {\"feature\": feature, \"a\": a, \"beta\": beta, \"y_star\": int(y_star), \"proba_star\": float(p_star)}\n",
    "\n",
    "def run_beta_for_profiles(\n",
    "    model, preprocessor, df_all, profiles_df, features_numeric, features_categorical,\n",
    "    threshold=0.5, n_samples=2000, random_state=42\n",
    "):\n",
    "    features = (features_numeric or []) + (features_categorical or [])\n",
    "    if not features:\n",
    "        return pd.DataFrame(index=profiles_df.index), pd.Series(dtype=float)\n",
    "\n",
    "    rows = []\n",
    "    for i in profiles_df.index:\n",
    "        row = profiles_df.loc[[i]]\n",
    "        row_result = {}\n",
    "        for feat in features:\n",
    "            res = beta_test_feature(\n",
    "                model, preprocessor, df_all, row, feat,\n",
    "                value=None, threshold=threshold,\n",
    "                n_samples=n_samples, random_state=random_state + i,\n",
    "            )\n",
    "            row_result[feat] = res[\"beta\"]\n",
    "        row_result[\"profile_index\"] = i\n",
    "        rows.append(row_result)\n",
    "\n",
    "    beta_table = pd.DataFrame(rows).set_index(\"profile_index\").sort_index()\n",
    "    beta_mean = beta_table.mean(axis=0)\n",
    "    return beta_table, beta_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3ec54",
   "metadata": {},
   "source": [
    "**Schritt 9** Erstellung des Profilsberichts\n",
    "\n",
    "Die Funktion def build_two_stage_profile_report_md baut einen lesbaren Markdown-Bericht:\n",
    "\n",
    "- Meta-Daten (Anzahl Profile, Schwelle β≥…)\n",
    "- Übersichts-Tabelle je Profil (Anzahl notwendiger / hinreichender Features pro Stufe)\n",
    "- Eine Detailtabellen je Profil (α=0/1, β-Wert, Indikator hinreichend)\n",
    "- Das ganze wird unter REPORT_PATH gespeichert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report-Builder (Markdown)\n",
    "def build_two_stage_profile_report_md(\n",
    "    alpha_econ: pd.DataFrame,\n",
    "    beta_econ: pd.DataFrame,\n",
    "    econ_features_all: list,\n",
    "    alpha_socio: pd.DataFrame,\n",
    "    beta_socio: pd.DataFrame,\n",
    "    socio_features_all: list,\n",
    "    suff_threshold: float = 0.7,\n",
    "    round_beta: int = 4,\n",
    "    out_path: str = REPORT_PATH\n",
    "):\n",
    "    idx_ref = alpha_econ.index\n",
    "    if not (idx_ref.equals(beta_econ.index) and idx_ref.equals(alpha_socio.index) and idx_ref.equals(beta_socio.index)):\n",
    "        raise ValueError(\"Indexmengen (Profile) von alpha_econ/beta_econ/alpha_socio/beta_socio müssen identisch sein.\")\n",
    "\n",
    "    econ_feats = [f for f in econ_features_all if f in alpha_econ.columns and f in beta_econ.columns]\n",
    "    socio_feats = [f for f in socio_features_all if f in alpha_socio.columns and f in beta_socio.columns]\n",
    "\n",
    "    md = []\n",
    "    md.append(\"# Profilbericht (zweistufig): α/β je Profil – Ökonomisch vs. Soziodemographisch\\n\")\n",
    "    md.append(f\"- **Anzahl Profile:** {len(idx_ref)}\")\n",
    "    md.append(f\"- **Hinreichend-Schwelle:** β ≥ {suff_threshold}\")\n",
    "    md.append(f\"- **Ökonomische Features:** {', '.join(econ_feats) if econ_feats else '(keine)'}\")\n",
    "    md.append(f\"- **Soziodemographische Features:** {', '.join(socio_feats) if socio_feats else '(keine)'}\\n\")\n",
    "\n",
    "    # Überblick je Profil\n",
    "    overview_rows = []\n",
    "    for pid in idx_ref:\n",
    "        row = {\"profile_index\": pid}\n",
    "        row[\"econ_alpha_cnt\"] = int(alpha_econ.loc[pid, econ_feats].sum()) if econ_feats else 0\n",
    "        row[\"econ_hinr_cnt\"]  = int((beta_econ.loc[pid, econ_feats] >= suff_threshold).sum()) if econ_feats else 0\n",
    "        row[\"socio_alpha_cnt\"] = int(alpha_socio.loc[pid, socio_feats].sum()) if socio_feats else 0\n",
    "        row[\"socio_hinr_cnt\"]  = int((beta_socio.loc[pid, socio_feats] >= suff_threshold).sum()) if socio_feats else 0\n",
    "        overview_rows.append(row)\n",
    "    overview_df = pd.DataFrame(overview_rows).set_index(\"profile_index\")\n",
    "    md.append(\"## Überblick (Anzahl notwendiger / hinreichender Features je Stufe)\\n\")\n",
    "    md.append(overview_df.to_markdown())\n",
    "    md.append(\"\\n---\\n\")\n",
    "\n",
    "    # Details je Profil\n",
    "    md.append(\"## Details je Profil\\n\")\n",
    "    for pid in idx_ref:\n",
    "        md.append(f\"\\n### Profil {pid}\\n\")\n",
    "\n",
    "        if econ_feats:\n",
    "            df_e = pd.DataFrame({\n",
    "                \"Feature\": econ_feats,\n",
    "                \"alpha_notwendig\": alpha_econ.loc[pid, econ_feats].astype(int).values,\n",
    "                \"beta\": np.round(beta_econ.loc[pid, econ_feats].astype(float).values, round_beta),\n",
    "            })\n",
    "            df_e[f\"hinreichend (β≥{suff_threshold:.2f})\"] = (df_e[\"beta\"] >= suff_threshold).astype(int)\n",
    "            md.append(\"\\n**Ökonomische Features**\\n\")\n",
    "            md.append(df_e.to_markdown(index=False))\n",
    "\n",
    "        if socio_feats:\n",
    "            df_s = pd.DataFrame({\n",
    "                \"Feature\": socio_feats,\n",
    "                \"alpha_notwendig\": alpha_socio.loc[pid, socio_feats].astype(int).values,\n",
    "                \"beta\": np.round(beta_socio.loc[pid, socio_feats].astype(float).values, round_beta),\n",
    "            })\n",
    "            df_s[f\"hinreichend (β≥{suff_threshold:.2f})\"] = (df_s[\"beta\"] >= suff_threshold).astype(int)\n",
    "            md.append(\"\\n**Soziodemographische/sonstige Features**\\n\")\n",
    "            md.append(df_s.to_markdown(index=False))\n",
    "\n",
    "        md.append(\"\\n---\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb8523d",
   "metadata": {},
   "source": [
    "**Schritt 10** Ausführung\n",
    "\n",
    "-  Hier wird die α/β-Evaluation getrennt für ökonomische und soziodemographische Feature-Sets ausgeführt.\n",
    "\n",
    "- Dann wird der finale Bericht als Markdown erzeugt und unter REPORT_PATH gespeichert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Zweistufiger Profilbericht gespeichert unter: c:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/profilbericht_alpha_beta_twostage.md\n"
     ]
    }
   ],
   "source": [
    "# Ausführung + Bericht\n",
    "alpha_econ, alpha_econ_mean = run_alpha_for_profiles(\n",
    "    model, preprocessor, df_all=X_all, profiles_df=profiles_df,\n",
    "    features_numeric=econ_num, features_categorical=econ_cat,\n",
    "    threshold=0.5, q_lo=0.05, q_hi=0.95, n_steps=9\n",
    ")\n",
    "beta_econ,  beta_econ_mean  = run_beta_for_profiles(\n",
    "    model, preprocessor, df_all=X_all, profiles_df=profiles_df,\n",
    "    features_numeric=econ_num, features_categorical=econ_cat,\n",
    "    threshold=0.5, n_samples=2000, random_state=42\n",
    ")\n",
    "\n",
    "alpha_socio, alpha_socio_mean = run_alpha_for_profiles(\n",
    "    model, preprocessor, df_all=X_all, profiles_df=profiles_df,\n",
    "    features_numeric=socio_num, features_categorical=socio_cat,\n",
    "    threshold=0.5, q_lo=0.05, q_hi=0.95, n_steps=9\n",
    ")\n",
    "beta_socio,  beta_socio_mean  = run_beta_for_profiles(\n",
    "    model, preprocessor, df_all=X_all, profiles_df=profiles_df,\n",
    "    features_numeric=socio_num, features_categorical=socio_cat,\n",
    "    threshold=0.5, n_samples=2000, random_state=4242\n",
    ")\n",
    "\n",
    "build_two_stage_profile_report_md(\n",
    "    alpha_econ=alpha_econ, beta_econ=beta_econ, econ_features_all=econ_num+econ_cat,\n",
    "    alpha_socio=alpha_socio, beta_socio=beta_socio, socio_features_all=socio_num+socio_cat,\n",
    "    suff_threshold=0.7, round_beta=4, out_path=REPORT_PATH\n",
    ")\n",
    "\n",
    "print(f\"💾 Zweistufiger Profilbericht gespeichert unter: {REPORT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
