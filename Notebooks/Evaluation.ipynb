{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27727,
     "status": "ok",
     "timestamp": 1757399160808,
     "user": {
      "displayName": "Jonny",
      "userId": "08198194125255586750"
     },
     "user_tz": -120
    },
    "id": "ECMVOq4zNxwg",
    "outputId": "f627dc3c-787e-4e54-c10d-d78801357564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell wurde erfolgreich geladen.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Pfad zum Modell\n",
    "model_path = 'C:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/german_credit_model.keras'\n",
    "\n",
    "# Modell laden\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "print(\"Modell wurde erfolgreich geladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tQYdSxd3jfTM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _predict_label_and_proba(model, preprocessor, row_df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Nimmt eine einzelne Zeile (DataFrame mit 1 Row), wendet den Preprocessor an,\n",
    "    gibt (label:int, proba:float) zurück.\n",
    "    \"\"\"\n",
    "    Xp = preprocessor.transform(row_df)\n",
    "    proba = float(model.predict(Xp, verbose=0)[0, 0])\n",
    "    label = int(proba >= threshold)\n",
    "    return label, proba\n",
    "\n",
    "def _numeric_grid_around(value, lo, hi, n_steps=9, strategy=\"quantiles\"):\n",
    "    \"\"\"\n",
    "    Erzeugt Testwerte (ohne Originalwert) in einem sinnvollen Bereich.\n",
    "    - strategy=\"quantiles\": nutzt [lo, hi] als Quantilsgrenzen (z.B. 5%–95%)\n",
    "    - strategy=\"relative\":  nutzt multiplikative Deltas um den Wert herum\n",
    "    \"\"\"\n",
    "    if strategy == \"quantiles\":\n",
    "        grid = np.linspace(lo, hi, n_steps)\n",
    "        # Originalwert rausfiltern, kleine numerische Toleranz\n",
    "        grid = [v for v in grid if abs(v - value) > 1e-12]\n",
    "        return grid\n",
    "\n",
    "    elif strategy == \"relative\":\n",
    "        deltas = np.array([-0.3, -0.2, -0.1, 0.1, 0.2, 0.3])  # anpassbar\n",
    "        grid = [(1 + d) * value for d in deltas]\n",
    "        return grid\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy {strategy}\")\n",
    "\n",
    "def alpha_test_numeric(model, preprocessor, df_row, feature, bounds, threshold=0.5,\n",
    "                       n_steps=9, strategy=\"quantiles\", clip_min=None):\n",
    "    \"\"\"\n",
    "    Testet Notwendigkeit eines NUMERISCHEN Features für EIN Profil.\n",
    "    - df_row: 1-Zeilen-DataFrame mit Originalspalten\n",
    "    - feature: Spaltenname (numerisch)\n",
    "    - bounds: (lo, hi) z.B. aus Trainings-Quantilen (5%, 95%)\n",
    "    - threshold: Klassifikationsschwelle\n",
    "    - strategy: \"quantiles\" oder \"relative\"\n",
    "    Rückgabe:\n",
    "      dict(is_necessary:bool, original_label:int, original_proba:float,\n",
    "           cf_value:float|None, cf_label:int|None, cf_proba:float|None)\n",
    "    \"\"\"\n",
    "    # Originalvorhersage\n",
    "    orig_label, orig_proba = _predict_label_and_proba(model, preprocessor, df_row, threshold)\n",
    "\n",
    "    lo, hi = bounds\n",
    "    value = float(df_row[feature].iloc[0])\n",
    "    test_values = _numeric_grid_around(value, lo, hi, n_steps=n_steps, strategy=strategy)\n",
    "\n",
    "    best = None  # (abs(change), new_value, new_label, new_proba)\n",
    "    for v in test_values:\n",
    "        v_clip = max(v, clip_min) if clip_min is not None else v\n",
    "        mod_row = df_row.copy()\n",
    "        mod_row.at[df_row.index[0], feature] = v_clip\n",
    "\n",
    "        new_label, new_proba = _predict_label_and_proba(model, preprocessor, mod_row, threshold)\n",
    "\n",
    "        if new_label != orig_label:\n",
    "            change = abs(v_clip - value)\n",
    "            if (best is None) or (change < best[0]):\n",
    "                best = (change, v_clip, new_label, new_proba)\n",
    "\n",
    "    if best is None:\n",
    "        return {\n",
    "            \"is_necessary\": False,\n",
    "            \"original_label\": orig_label,\n",
    "            \"original_proba\": orig_proba,\n",
    "            \"cf_value\": None,\n",
    "            \"cf_label\": None,\n",
    "            \"cf_proba\": None\n",
    "        }\n",
    "    else:\n",
    "        _, v_star, l_star, p_star = best\n",
    "        return {\n",
    "            \"is_necessary\": True,\n",
    "            \"original_label\": orig_label,\n",
    "            \"original_proba\": orig_proba,\n",
    "            \"cf_value\": v_star,\n",
    "            \"cf_label\": l_star,\n",
    "            \"cf_proba\": p_star\n",
    "        }\n",
    "\n",
    "def alpha_test_categorical(model, preprocessor, df_row, feature, all_categories, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Testet Notwendigkeit eines KATEGORIALEN Features für EIN Profil.\n",
    "    - df_row: 1-Zeilen-DataFrame\n",
    "    - feature: Spaltenname (kategorial)\n",
    "    - all_categories: Liste aller im Training beobachteten Kategorien\n",
    "    Rückgabe analog zu alpha_test_numeric, cf_value ist dann die neue Kategorie.\n",
    "    \"\"\"\n",
    "    orig_label, orig_proba = _predict_label_and_proba(model, preprocessor, df_row, threshold)\n",
    "    current_cat = df_row[feature].iloc[0]\n",
    "\n",
    "    best = None  # (new_cat, new_label, new_proba)\n",
    "    for cat in all_categories:\n",
    "        if cat == current_cat:\n",
    "            continue\n",
    "        mod_row = df_row.copy()\n",
    "        mod_row.at[df_row.index[0], feature] = cat\n",
    "\n",
    "        new_label, new_proba = _predict_label_and_proba(model, preprocessor, mod_row, threshold)\n",
    "        if new_label != orig_label:\n",
    "            best = (cat, new_label, new_proba)\n",
    "            break  # erste Änderung reicht als „notwendig“\n",
    "\n",
    "    if best is None:\n",
    "        return {\n",
    "            \"is_necessary\": False,\n",
    "            \"original_label\": orig_label,\n",
    "            \"original_proba\": orig_proba,\n",
    "            \"cf_value\": None,\n",
    "            \"cf_label\": None,\n",
    "            \"cf_proba\": None\n",
    "        }\n",
    "    else:\n",
    "        cat_star, l_star, p_star = best\n",
    "        return {\n",
    "            \"is_necessary\": True,\n",
    "            \"original_label\": orig_label,\n",
    "            \"original_proba\": orig_proba,\n",
    "            \"cf_value\": cat_star,   # neue Kategorie\n",
    "            \"cf_label\": l_star,\n",
    "            \"cf_proba\": p_star\n",
    "        }\n",
    "\n",
    "# =========================\n",
    "#   ALPHA für 10×6 laufen\n",
    "# =========================\n",
    "\n",
    "def run_alpha_for_profiles(\n",
    "    model, preprocessor, df_all, profiles_df,  # df_all = kompletter Trainings-DF (für Quantile & Kategorien)\n",
    "    features_numeric, features_categorical,\n",
    "    threshold=0.5, q_lo=0.05, q_hi=0.95,\n",
    "    n_steps=9, num_strategy=\"quantiles\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Führt den Alpha-Test (Notwendigkeit) über mehrere Profile × Features aus.\n",
    "    - model, preprocessor: dein eingefrorenes Modell & Preprocessor (fit auf Training)\n",
    "    - df_all: kompletter Trainings-DataFrame (Originalkodierung), um Quantile/Kategorien zu bestimmen\n",
    "    - profiles_df: DataFrame mit GENAU den 10 Profilen (Originalkodierung, gleiche Spaltenreihenfolge)\n",
    "    - features_*: Listen deiner ausgewählten Features\n",
    "    - threshold: Klassifikationsschwelle\n",
    "    - q_lo, q_hi: Quantile für numerische Testbereiche (z. B. 5%–95%)\n",
    "    - n_steps, num_strategy: Grid-Parameter für numerische Variation\n",
    "    Rückgabe:\n",
    "      results_table: DataFrame (Profile × Features) mit {0/1} (nicht notwendig/ notwendig)\n",
    "      details: verschachteltes Dict mit Zusatzinfos (z. B. minimaler Gegenfakt, Probas)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Vorbereitung: Quantile-Bereiche & Kategorie-Listen aus Training ---\n",
    "    num_bounds = {}\n",
    "    for feat in features_numeric:\n",
    "        lo = df_all[feat].quantile(q_lo)\n",
    "        hi = df_all[feat].quantile(q_hi)\n",
    "        num_bounds[feat] = (float(lo), float(hi))\n",
    "\n",
    "    cat_values = {}\n",
    "    for feat in features_categorical:\n",
    "        # nur im Training gesehene Kategorien testen (robust ggü. OneHot)\n",
    "        cat_values[feat] = sorted(df_all[feat].dropna().unique().tolist())\n",
    "\n",
    "    # --- 2) Ergebnis-Container ---\n",
    "    rows = []\n",
    "    details = {}  # details[(profile_idx, feature)] = dict(...)\n",
    "\n",
    "    # --- 3) Schleife: Profile × Features ---\n",
    "    for i in profiles_df.index:\n",
    "        row = profiles_df.loc[[i]]  # 1-Zeilen-DataFrame\n",
    "        row_result = {}\n",
    "\n",
    "        # Numerische Features\n",
    "        for feat in features_numeric:\n",
    "            res = alpha_test_numeric(\n",
    "                model, preprocessor, row, feature=feat, bounds=num_bounds[feat],\n",
    "                threshold=threshold, n_steps=n_steps, strategy=num_strategy, clip_min=0.0\n",
    "            )\n",
    "            row_result[feat] = int(res[\"is_necessary\"])\n",
    "            details[(i, feat)] = res\n",
    "\n",
    "        # Kategoriale Features\n",
    "        for feat in features_categorical:\n",
    "            res = alpha_test_categorical(\n",
    "                model, preprocessor, row, feature=feat,\n",
    "                all_categories=cat_values[feat], threshold=threshold\n",
    "            )\n",
    "            row_result[feat] = int(res[\"is_necessary\"])\n",
    "            details[(i, feat)] = res\n",
    "\n",
    "        # Zeile mit Profil-ID sammeln\n",
    "        row_result[\"profile_index\"] = i\n",
    "        rows.append(row_result)\n",
    "\n",
    "    # --- 4) Tabelle bauen (Profile × Features) ---\n",
    "    results_table = pd.DataFrame(rows).set_index(\"profile_index\").sort_index()\n",
    "\n",
    "    # --- 5) Alpha je Feature (Anteil notwendiger Fälle) optional gleich mit ausrechnen\n",
    "    alpha_per_feature = results_table.mean(axis=0).rename(\"alpha_rate\")\n",
    "    print(\"\\nα (Notwendigkeit) – Anteil notwendiger Fälle pro Feature:\")\n",
    "    print(alpha_per_feature.sort_values(ascending=False).to_string())\n",
    "\n",
    "    return results_table, details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1757405038927,
     "user": {
      "displayName": "Jonny",
      "userId": "08198194125255586750"
     },
     "user_tz": -120
    },
    "id": "km9-5aQqgL1f",
    "outputId": "03ac4824-7deb-4686-f2b1-0be4da325acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Zweistufiger Profilbericht gespeichert unter: C:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/profilbericht_alpha_beta_twostage.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ÖKONOMISCHE FEATURES (12)\n",
    "econ_features_all = [\n",
    "    \"Kreditbetrag\",\n",
    "    \"Kreditgeschichte\",\n",
    "    \"Kreditverwendungszweck\",\n",
    "    \"Dauer_in_Monaten\",\n",
    "    \"Ratenhöhe\",\n",
    "    \"Sparkonto_Wertpapiere\",\n",
    "    \"Vermögen\",\n",
    "    \"Status_des_Girokontos\",\n",
    "    \"Beschäftigt_seit\",\n",
    "    \"Andere_Ratenverpflichtungen\",\n",
    "    \"Weitere_Bürgen_Schuldner\",\n",
    "    \"Anzahl_bestehender_Kredite\",\n",
    "]\n",
    "\n",
    "# SOZIODEMOGRAPHISCHE/SONSTIGE FEATURES (8)\n",
    "socio_features_all = [\n",
    "    \"Alter\",\n",
    "    \"Familienstand_Geschlecht\",\n",
    "    \"Wohnsitzdauer\",\n",
    "    \"Wohnsituation\",\n",
    "    \"Unterhaltspflichtige_Personen\",\n",
    "    \"Telefon\",\n",
    "    \"Ausländischer_Arbeiter\",\n",
    "    \"Beruf\",\n",
    "]\n",
    "\n",
    "\n",
    "def build_two_stage_profile_report_md(\n",
    "    alpha_econ: pd.DataFrame,\n",
    "    beta_econ: pd.DataFrame,\n",
    "    econ_features_all: list,              # Reihenfolge für ökonomische Features\n",
    "    alpha_socio: pd.DataFrame,\n",
    "    beta_socio: pd.DataFrame,\n",
    "    socio_features_all: list,             # Reihenfolge für soziodemographische Features\n",
    "    suff_threshold: float = 0.7,\n",
    "    round_beta: int = 4,\n",
    "    out_path: str = 'C:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/two_stage_profile_report.md'\n",
    "):\n",
    "    # --- Sanity ---\n",
    "    for name, obj in [\n",
    "        (\"alpha_econ\", alpha_econ), (\"beta_econ\", beta_econ),\n",
    "        (\"alpha_socio\", alpha_socio), (\"beta_socio\", beta_socio)\n",
    "    ]:\n",
    "        if not isinstance(obj, pd.DataFrame):\n",
    "            raise TypeError(f\"{name} ist kein DataFrame, sondern {type(obj)}\")\n",
    "\n",
    "    # Profile-Mengen müssen übereinstimmen\n",
    "    idx_ref = alpha_econ.index\n",
    "    if not (idx_ref.equals(beta_econ.index) and idx_ref.equals(alpha_socio.index) and idx_ref.equals(beta_socio.index)):\n",
    "        raise ValueError(\"Die Indexmengen (Profile) von alpha_econ/beta_econ/alpha_socio/beta_socio sind nicht identisch.\")\n",
    "\n",
    "    # Features, die tatsächlich vorhanden sind (Schnittmenge mit DataFrames)\n",
    "    econ_feats = [f for f in econ_features_all if f in alpha_econ.columns and f in beta_econ.columns]\n",
    "    socio_feats = [f for f in socio_features_all if f in alpha_socio.columns and f in beta_socio.columns]\n",
    "\n",
    "    if not econ_feats and not socio_feats:\n",
    "        raise ValueError(\"Weder ökonomische noch soziodemographische Features wurden in den Matrizen gefunden.\")\n",
    "\n",
    "    md = []\n",
    "    md.append(\"# Profilbericht (zweistufig): α/β je Profil – Ökonomisch vs. Soziodemographisch\\n\")\n",
    "    md.append(f\"- **Anzahl Profile:** {len(idx_ref)}\")\n",
    "    md.append(f\"- **Hinreichend-Schwelle:** β ≥ {suff_threshold}\")\n",
    "    md.append(f\"- **Ökonomische Features:** {', '.join(econ_feats) if econ_feats else '(keine)'}\")\n",
    "    md.append(f\"- **Soziodemographische Features:** {', '.join(socio_feats) if socio_feats else '(keine)'}\\n\")\n",
    "\n",
    "    # --- Optionale Gesamtübersicht je Profil (Aggregationswerte) ---\n",
    "    overview_rows = []\n",
    "    for pid in idx_ref:\n",
    "        row = {\"profile_index\": pid}\n",
    "        if econ_feats:\n",
    "            row[\"econ_alpha_cnt\"] = int(alpha_econ.loc[pid, econ_feats].sum())\n",
    "            row[\"econ_hinr_cnt\"]  = int((beta_econ.loc[pid, econ_feats] >= suff_threshold).sum())\n",
    "        else:\n",
    "            row[\"econ_alpha_cnt\"] = 0\n",
    "            row[\"econ_hinr_cnt\"]  = 0\n",
    "\n",
    "        if socio_feats:\n",
    "            row[\"socio_alpha_cnt\"] = int(alpha_socio.loc[pid, socio_feats].sum())\n",
    "            row[\"socio_hinr_cnt\"]  = int((beta_socio.loc[pid, socio_feats] >= suff_threshold).sum())\n",
    "        else:\n",
    "            row[\"socio_alpha_cnt\"] = 0\n",
    "            row[\"socio_hinr_cnt\"]  = 0\n",
    "\n",
    "        overview_rows.append(row)\n",
    "\n",
    "    overview_df = pd.DataFrame(overview_rows).set_index(\"profile_index\")\n",
    "    md.append(\"## Überblick (Anzahl notwendiger / hinreichender Features je Stufe)\\n\")\n",
    "    md.append(overview_df.to_markdown())\n",
    "    md.append(\"\\n---\\n\")\n",
    "\n",
    "    # --- Detail je Profil: zwei Tabellen (Ökonomisch / Soziodemographisch) ---\n",
    "    md.append(\"## Details je Profil\\n\")\n",
    "    for pid in idx_ref:\n",
    "        md.append(f\"\\n### Profil {pid}\\n\")\n",
    "\n",
    "        if econ_feats:\n",
    "            df_e = pd.DataFrame({\n",
    "                \"Feature\": econ_feats,\n",
    "                \"alpha_notwendig\": alpha_econ.loc[pid, econ_feats].astype(int).values,\n",
    "                \"beta\": np.round(beta_econ.loc[pid, econ_feats].astype(float).values, round_beta),\n",
    "            })\n",
    "            df_e[\"hinreichend (β≥{:.2f})\".format(suff_threshold)] = (df_e[\"beta\"] >= suff_threshold).astype(int)\n",
    "            md.append(\"\\n**Ökonomische Features**\\n\")\n",
    "            md.append(df_e.to_markdown(index=False))\n",
    "\n",
    "        if socio_feats:\n",
    "            df_s = pd.DataFrame({\n",
    "                \"Feature\": socio_feats,\n",
    "                \"alpha_notwendig\": alpha_socio.loc[pid, socio_feats].astype(int).values,\n",
    "                \"beta\": np.round(beta_socio.loc[pid, socio_feats].astype(float).values, round_beta),\n",
    "            })\n",
    "            df_s[\"hinreichend (β≥{:.2f})\".format(suff_threshold)] = (df_s[\"beta\"] >= suff_threshold).astype(int)\n",
    "            md.append(\"\\n**Soziodemographische/sonstige Features**\\n\")\n",
    "            md.append(df_s.to_markdown(index=False))\n",
    "\n",
    "        md.append(\"\\n---\")\n",
    "\n",
    "    # --- Datei schreiben ---\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(md))\n",
    "    print(f\"💾 Zweistufiger Profilbericht gespeichert unter: {out_path}\")\n",
    "\n",
    "\n",
    "# ===== Aufruf mit deinen vorhandenen Objekten =====\n",
    "# Annahmen: alpha_econ, beta_econ, alpha_socio, beta_socio, economic_features_all, socio_features_all existieren\n",
    "build_two_stage_profile_report_md(\n",
    "    alpha_econ=alpha_econ,\n",
    "    beta_econ=beta_econ,\n",
    "    econ_features_all=econ_features_all,      # <- hier korrigiert\n",
    "    alpha_socio=alpha_socio,\n",
    "    beta_socio=beta_socio,\n",
    "    socio_features_all=socio_features_all,\n",
    "    suff_threshold=0.7,\n",
    "    round_beta=4,\n",
    "    out_path='C:/Users/JonasNiehus/Documents/Masterarbeit/Evaluation/Ergebnisse/profilbericht_alpha_beta_twostage.md'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdb0wMToi4c7iDheXXkrD0",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
